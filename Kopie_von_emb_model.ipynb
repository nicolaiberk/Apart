{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Kopie von emb_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolaiberk/Apart/blob/master/Kopie_von_emb_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFN_mXswfF-D",
        "outputId": "1220318e-fca1-4333-eb5f-648a6b4f28dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "GFN_mXswfF-D",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5825374-c511-47fe-a2e4-da9bd8431a6d",
        "outputId": "1e960389-34ee-4094-be3d-d181dc0775cb"
      },
      "source": [
        "## estimate word embeddings from newspaper data\n",
        "## code adapted from https://github.com/damian0604/embeddingworkshop/blob/main/04exercise.ipynb\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import string\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import sys\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "\n",
        "# tqdm allows you to display progress bars in loops\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "import gensim\n",
        "\n",
        "# lets get more output\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "id": "c5825374-c511-47fe-a2e4-da9bd8431a6d",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11c85d9f-4750-470f-8ff8-a0a91dc705c6",
        "outputId": "d51c6c76-4ca8-49a6-892d-7477e72748a4"
      },
      "source": [
        "# get full set of news articles\n",
        "!rm sample_data -r\n",
        "!mkdir newspapers\n",
        "!wget -O newspapers/articles.zip https://www.dropbox.com/sh/r6k4qk9flgz0agu/AAA5ZLsuOwk9UWiEsLAOFmDSa?dl=0\n",
        "!unzip newspapers/articles.zip -d newspapers\n",
        "!rm newspapers/articles.zip"
      ],
      "id": "11c85d9f-4750-470f-8ff8-a0a91dc705c6",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'sample_data': No such file or directory\n",
            "mkdir: cannot create directory ‘newspapers’: File exists\n",
            "--2021-07-21 14:56:34--  https://www.dropbox.com/sh/r6k4qk9flgz0agu/AAA5ZLsuOwk9UWiEsLAOFmDSa?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6022:18::a27d:4212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/r6k4qk9flgz0agu/AAA5ZLsuOwk9UWiEsLAOFmDSa [following]\n",
            "--2021-07-21 14:56:34--  https://www.dropbox.com/sh/raw/r6k4qk9flgz0agu/AAA5ZLsuOwk9UWiEsLAOFmDSa\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc9b0c4cbce8c01fa4691badc1fc.dl.dropboxusercontent.com/zip_download_get/A2GRIZo_RIm7MS3-tMOJGoumoX9lzjvLliMsrE9B43vDO4bEKYQCApe6KZLu9mtt-Io1JABsWgKt-ygi8cWr_BS0z3-gkv2oDW4ltpYPwEeRMw# [following]\n",
            "--2021-07-21 14:56:34--  https://uc9b0c4cbce8c01fa4691badc1fc.dl.dropboxusercontent.com/zip_download_get/A2GRIZo_RIm7MS3-tMOJGoumoX9lzjvLliMsrE9B43vDO4bEKYQCApe6KZLu9mtt-Io1JABsWgKt-ygi8cWr_BS0z3-gkv2oDW4ltpYPwEeRMw\n",
            "Resolving uc9b0c4cbce8c01fa4691badc1fc.dl.dropboxusercontent.com (uc9b0c4cbce8c01fa4691badc1fc.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc9b0c4cbce8c01fa4691badc1fc.dl.dropboxusercontent.com (uc9b0c4cbce8c01fa4691badc1fc.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6202295648 (5.8G) [application/zip]\n",
            "Saving to: ‘newspapers/articles.zip’\n",
            "\n",
            "newspapers/articles 100%[===================>]   5.78G  70.3MB/s    in 75s     \n",
            "\n",
            "2021-07-21 14:57:50 (79.0 MB/s) - ‘newspapers/articles.zip’ saved [6202295648/6202295648]\n",
            "\n",
            "Archive:  newspapers/articles.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: newspapers/_sz_articles.csv  \n",
            " extracting: newspapers/_taz_articles.csv  \n",
            " extracting: newspapers/_faz_articles.csv  \n",
            " extracting: newspapers/_spon_articles.csv  \n",
            " extracting: newspapers/_bild_articles.csv  \n",
            " extracting: newspapers/_sz_articles_2019.csv  \n",
            " extracting: newspapers/_taz_articles_2019.csv  \n",
            " extracting: newspapers/_faz_articles_2019.csv  \n",
            " extracting: newspapers/_bild_articles_2019.csv  \n",
            " extracting: newspapers/_spon_articles_2019.csv  \n",
            " extracting: newspapers/_weltonline_articles.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz3OYCGmcSXU",
        "outputId": "c773b16d-b5e2-4d49-efce-ebd5b8f4c145"
      },
      "source": [
        "# load all texts\n",
        "if 'artcls' in locals():\n",
        "  del(artcls)\n",
        "\n",
        "for filename in tqdm(os.listdir('newspapers')):\n",
        "  if 'artcls' in locals():\n",
        "    print(f'\\nLoaded {artcls.shape[0]} articles')\n",
        "    artcls = artcls.append(pd.read_csv('newspapers/'+filename))\n",
        "  else:\n",
        "    artcls = pd.read_csv('newspapers/'+filename)\n",
        "print(f'Loaded {artcls.shape[0]} articles, done.')"
      ],
      "id": "lz3OYCGmcSXU",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  9%|▉         | 1/11 [00:07<01:14,  7.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 263266 articles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 2/11 [00:20<01:22,  9.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 575291 articles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 3/11 [00:27<01:09,  8.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 794334 articles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▋      | 4/11 [00:30<00:47,  6.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 893180 articles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 5/11 [00:38<00:43,  7.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 1220020 articles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 6/11 [00:41<00:29,  5.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 1285387 articles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▎   | 7/11 [00:49<00:26,  6.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 1436035 articles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 8/11 [00:52<00:16,  5.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 1472453 articles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 9/11 [00:55<00:09,  4.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 1545861 articles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 10/11 [00:56<00:03,  3.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 1634513 articles\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11/11 [01:12<00:00,  6.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded 2474182 articles, done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "wPBsxGmEgp1W",
        "outputId": "d4bf31d9-08b9-4a9d-ab27-679be4d402b1"
      },
      "source": [
        "artcls = artcls.reset_index()\n",
        "artcls.text[0]"
      ],
      "id": "wPBsxGmEgp1W",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'was fehlt ... ... der Vorsatz    Der Vorsatz hat keinen guten Klang: Mit Vorsatz gehandelt zu haben, wird einem meist im Gericht vorgeworfen. Auch die guten Vorsätze haben immer den unangenehmen Beigeschmack von Schuld und Sühne - nicht zuletzt, weil sie zu 90 Prozent gebrochen werden. Woher der Brauch kommt, sich im neuen Jahr eine Änderung des Verhaltens vorzunehmen, ist unklar.    Am wahrscheinlichsten ist ein christlicher Ursprung, wie bei vielen Festtagsbräuchen - immerhin stammt das Wort Silvester vom Namenstag des Papstes Silvester (lateinisch für \"Waldmensch\"), der am 31. Dezember 335 starb. Möglicherweise sind die guten Vorsätze also eine katholische Erfindung: Die Sünden werden vergeben, aber nur, wenn man Besserung gelobt.    Die Wortherkunft der guten Vorsätze ist leichter zu bestimmen: Die Wurzel des Guten liegt im germanischen \"goda\" (passend, geeignet), das sich im 8. Jahrhundert zu \"guot\" (Besitz, Vermögen) weiterentwickelte. Vorsätze hießen im Mittelhochdeutschen \"vürsaz\" (Vorhaben, Absicht) und sind vom althochdeutschen \"sezzen\" (aufstellen, festlegen) abgeleitet, welches wiederum vom germanischen \"set-ja\" (sitzen) abstammt.    Was man gut findet, also was einem gerade \"passt\", kann morgen schon wieder stören, wie es mit den guten Vorsätzen meist ist. Schöner als das säuerlich-christliche Bekenntnis zur Besserung wäre es ohnehin, die Tabula rasa des neuen Jahres zu nutzen, um den in einigen Kulturen verbreiteten Brauch zu praktizieren, allen Streit und Ärger des vergangenen Jahres zu vergessen, alle Schuld zu erlassen, alle Fehler zu vergeben - ohne Gegenleistung. Wäre das nicht mal ein guter Vorsatz? (WENK)    '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myJ1k4uEvZSb",
        "outputId": "9cc84265-40fe-4d12-f52f-a07694e18ce7"
      },
      "source": [
        "artcls.shape"
      ],
      "id": "myJ1k4uEvZSb",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2474182, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "p4w1ixMvg7Zl",
        "outputId": "41912568-ffb8-4189-9af6-55df7cd5d5bf"
      },
      "source": [
        "# check if string\n",
        "stringvar = [str == type(i) for i in artcls.text]\n",
        "artcls = artcls[stringvar]\n",
        "\n",
        "# cut into sentences\n",
        "trans = str.maketrans('', '', string.punctuation) # translation scheme for removing punctuation\n",
        "uniquesentences = set()\n",
        "for review in tqdm(artcls.text):\n",
        "    for sentence in sent_tokenize(review):\n",
        "        # remove HTML tags in there\n",
        "        sentence = re.sub(r\"<.*?>\",\" \",sentence)\n",
        "        sentence = sentence.translate(trans) \n",
        "        if sentence not in uniquesentences:\n",
        "            uniquesentences.add(sentence.lower())\n",
        "\n",
        "print(f\"We now have {len(uniquesentences)} unique sentences.\")"
      ],
      "id": "p4w1ixMvg7Zl",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 1179004/2214853 [29:38<23:18, 740.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-50167cd9ae89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# remove HTML tags in there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"<.*?>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muniquesentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0muniquesentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrSZs-UZ5UoU"
      },
      "source": [
        "del(artcls)"
      ],
      "id": "OrSZs-UZ5UoU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIRoSblgFC8H"
      },
      "source": [
        "with open('drive/MyDrive/Bild/uniquesentences.txt', mode='w') as fo:\n",
        "  writer = csv.writer(fo)\n",
        "  for sentence in uniquesentences:\n",
        "    writer.writerow(sentence)\n",
        "\n",
        "del(uniquesentences)"
      ],
      "id": "RIRoSblgFC8H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k91FQsjGsLxd"
      },
      "source": [
        "tokenizedsentences = []\n",
        "\n",
        "with open('drive/MyDrive/Bild/uniquesentences.txt', mode='r') as fi:\n",
        "  reader = csv.reader(fi)\n",
        "  for sentence in reader:\n",
        "    tokenizedsentences.append(sentence.split())"
      ],
      "id": "k91FQsjGsLxd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9LWsu42r4w9",
        "outputId": "ea5a8c4b-ae8d-4c63-f507-d0c5d30204ee"
      },
      "source": [
        "with open('drive/MyDrive/uniquesentences.txt', mode='r') as fi:\n",
        "  reader = csv.reader(fi)\n",
        "  for sentence in reader:\n",
        "    print(sentence)\n",
        "    break"
      ],
      "id": "U9LWsu42r4w9",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Crl7zfraiK"
      },
      "source": [
        "tokenizedsentences[0]"
      ],
      "id": "y9Crl7zfraiK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spkoV479rBV9"
      },
      "source": [
        "print(f\"Started setting up the model at {datetime.now()}\")\n",
        "model = gensim.models.Word2Vec(size=300, min_count=100) # we want 300 dimensions and not overdo it with the features\n",
        "model.build_vocab(tokenizedsentences)\n",
        "print(f\"Started training at {datetime.now()}\")\n",
        "model.train(tokenizedsentences, total_examples=model.corpus_count,  epochs=5)\n",
        "# our model gets better if we use more epochs, but we can only do so if we use a list instead of a generator as input\n",
        "# after all, you can only pass over a generator once.\n",
        "# model.train(tokenizedsentences2, total_examples=model.corpus_count,  epochs=model.epochs)\n",
        "print(f\"Finished training at {datetime.now()}\")"
      ],
      "id": "spkoV479rBV9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-2XB8dQu6Cl"
      },
      "source": [
        "model.save(\"np_emb\")"
      ],
      "id": "J-2XB8dQu6Cl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D48soN0JQRKa"
      },
      "source": [
        "model.save(\"drive/MyDrive/Bild/np_emb\")"
      ],
      "id": "D48soN0JQRKa",
      "execution_count": null,
      "outputs": []
    }
  ]
}